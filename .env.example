# ===========================
# AI Content Project Configuration
# ===========================

# Ollama Configuration
# --------------------
# URL where Ollama server is running
OLLAMA_URL=http://localhost:11434

# Primary Llama 3 model to use
MODEL_NAME=llama3:8b

# Comma-separated list of fallback models if primary is unavailable
FALLBACK_MODELS=llama3.2:3b,llama3:latest

# API Configuration
# -----------------
# Base URL for the FastAPI application (used by smoke tests)
API_URL=http://127.0.0.1:8000

# Support Agent Testing
# ---------------------
# Default topic for support_smoketest.py
SUPPORT_TOPIC=unable to log into account

# Default tone for support_smoketest.py (neutral | empathetic | formal | friendly)
SUPPORT_TONE=empathetic

# Environment & Logging
# ---------------------
APP_ENV=development
LOG_LEVEL=INFO
